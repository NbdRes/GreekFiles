# ═══════════════════════════════════════════════════════════
# ניתוח ציטוטים מהיר - גרסה יציבה ללא Shiny
# ═══════════════════════════════════════════════════════════

# התקנת חבילות
packages <- c("openxlsx", "ggplot2", "rstudioapi", 
              "igraph", "visNetwork", "wordcloud", "treemap")

for (pkg in packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
}

# טעינת ספריות
library(openxlsx)
library(ggplot2)
library(rstudioapi)
library(igraph)
library(visNetwork)
library(wordcloud)
library(treemap)

# ═══════════════════════════════════════════════════════════
# פונקציות עזר
# ═══════════════════════════════════════════════════════════

remove_greek_accents <- function(text) {
  accents_map <- c(
    "ά" = "α", "ὰ" = "α", "ᾶ" = "α", "ἀ" = "α", "ἁ" = "α", 
    "ἄ" = "α", "ἅ" = "α", "ἂ" = "α", "ἃ" = "α", "ᾳ" = "α",
    "ᾴ" = "α", "ᾲ" = "α", "ᾷ" = "α", "ἆ" = "α", "ἇ" = "α",
    "Ά" = "Α", "Ἀ" = "Α", "Ἁ" = "Α", "Ἄ" = "Α", "Ἅ" = "Α",
    "έ" = "ε", "ὲ" = "ε", "ἐ" = "ε", "ἑ" = "ε", "ἔ" = "ε",
    "ἕ" = "ε", "ἒ" = "ε", "ἓ" = "ε",
    "Έ" = "Ε", "Ἐ" = "Ε", "Ἑ" = "Ε", "Ἔ" = "Ε", "Ἕ" = "Ε",
    "ή" = "η", "ὴ" = "η", "ῆ" = "η", "ἠ" = "η", "ἡ" = "η",
    "ἤ" = "η", "ἥ" = "η", "ἢ" = "η", "ἣ" = "η", "ῃ" = "η",
    "ῄ" = "η", "ῂ" = "η", "ῇ" = "η", "ἦ" = "η", "ἧ" = "η",
    "Ή" = "Η", "Ἠ" = "Η", "Ἡ" = "Η", "Ἤ" = "Η", "Ἥ" = "Η",
    "ί" = "ι", "ὶ" = "ι", "ῖ" = "ι", "ἰ" = "ι", "ἱ" = "ι",
    "ἴ" = "ι", "ἵ" = "ι", "ἲ" = "ι", "ἳ" = "ι", "ϊ" = "ι",
    "ΐ" = "ι", "ῒ" = "ι", "ῗ" = "ι", "ἶ" = "ι", "ἷ" = "ι",
    "Ί" = "Ι", "Ἰ" = "Ι", "Ἱ" = "Ι", "Ἴ" = "Ι", "Ἵ" = "Ι", "Ϊ" = "Ι",
    "ό" = "ο", "ὸ" = "ο", "ὀ" = "ο", "ὁ" = "ο", "ὄ" = "ο",
    "ὅ" = "ο", "ὂ" = "ο", "ὃ" = "ο",
    "Ό" = "Ο", "Ὀ" = "Ο", "Ὁ" = "Ο", "Ὄ" = "Ο", "Ὅ" = "Ο",
    "ύ" = "υ", "ὺ" = "υ", "ῦ" = "υ", "ὐ" = "υ", "ὑ" = "υ",
    "ὔ" = "υ", "ὕ" = "υ", "ὒ" = "υ", "ὓ" = "υ", "ϋ" = "υ",
    "ΰ" = "υ", "ῢ" = "υ", "ῧ" = "υ", "ὖ" = "υ", "ὗ" = "υ",
    "Ύ" = "Υ", "Ὑ" = "Υ", "Ὕ" = "Υ", "Ϋ" = "Υ",
    "ώ" = "ω", "ὼ" = "ω", "ῶ" = "ω", "ὠ" = "ω", "ὡ" = "ω",
    "ὤ" = "ω", "ὥ" = "ω", "ὢ" = "ω", "ὣ" = "ω", "ῳ" = "ω",
    "ῴ" = "ω", "ῲ" = "ω", "ῷ" = "ω", "ὦ" = "ω", "ὧ" = "ω",
    "Ώ" = "Ω", "Ὠ" = "Ω", "Ὡ" = "Ω", "Ὤ" = "Ω", "Ὥ" = "Ω",
    "ῤ" = "ρ", "ῥ" = "ρ", "Ῥ" = "Ρ"
  )
  
  for (accented in names(accents_map)) {
    text <- gsub(accented, accents_map[accented], text, fixed = TRUE)
  }
  
  return(text)
}

select_source_file <- function() {
  message("\n╔════════════════════════════════════════════════╗")
  message("║  שלב 1: בחירת קובץ המקור (יוסף בן מתיתיהו)   ║")
  message("╚════════════════════════════════════════════════╝")
  
  file_path <- selectFile(caption = "בחר קובץ מקור (TXT)", 
                          filter = "Text Files (*.txt)",
                          existing = TRUE)
  
  if (is.null(file_path) || file_path == "") {
    stop("\n✗ לא נבחר קובץ מקור")
  }
  
  message(paste("\n✓ נבחר קובץ מקור:", basename(file_path)))
  return(file_path)
}

select_target_folder <- function() {
  message("\n╔════════════════════════════════════════════════╗")
  message("║  שלב 2: בחירת תיקיית היעד (כותבים נוצריים)   ║")
  message("╚════════════════════════════════════════════════╝")
  
  folder_path <- selectDirectory(caption = "בחר תיקיית יעד")
  
  if (is.null(folder_path) || folder_path == "") {
    stop("\n✗ לא נבחרה תיקייה")
  }
  
  message(paste("\n✓ נבחרה תיקייה:", folder_path))
  return(folder_path)
}

# ═══════════════════════════════════════════════════════════
# בחירת פרמטרים - קונסול פשוט (יציב ב-macOS M1)
# ═══════════════════════════════════════════════════════════

get_analysis_parameters <- function(source_file, target_folder) {
  
  message("\n╔════════════════════════════════════════════════╗")
  message("║  שלב 3: הגדרת פרמטרים                         ║")
  message("╚════════════════════════════════════════════════╝\n")
  
  # יצירת שם ברירת מחדל
  source_name <- tools::file_path_sans_ext(basename(source_file))
  target_name <- basename(target_folder)
  default_name <- paste(source_name, target_name, sep = "-")
  
  # שם הבדיקה
  cat("שם הבדיקה [ברירת מחדל:", default_name, "]: ")
  analysis_name <- readline()
  if (analysis_name == "" || is.null(analysis_name)) {
    analysis_name <- default_name
  }
  
  # N-gram size
  cat("מספר מילים ב-n-gram [ברירת מחדל: 6]: ")
  ngram_input <- readline()
  if (ngram_input == "" || is.null(ngram_input)) {
    ngram_size <- 6
  } else {
    ngram_size <- as.integer(ngram_input)
    if (is.na(ngram_size) || ngram_size < 3 || ngram_size > 20) {
      message("ערך לא תקין, משתמש בברירת מחדל: 6")
      ngram_size <- 6
    }
  }
  
  # Similarity threshold
  cat("סף דמיון מינימלי 0-1 [ברירת מחדל: 0.95]: ")
  similarity_input <- readline()
  if (similarity_input == "" || is.null(similarity_input)) {
    similarity <- 0.95
  } else {
    similarity <- as.numeric(similarity_input)
    if (is.na(similarity) || similarity < 0.5 || similarity > 1.0) {
      message("ערך לא תקין, משתמש בברירת מחדל: 0.95")
      similarity <- 0.95
    }
  }
  
  return(list(
    name = analysis_name,
    ngram_size = ngram_size,
    similarity = similarity
  ))
}

fast_read_file <- function(file_path) {
  tryCatch({
    content <- readLines(file_path, warn = FALSE, encoding = "UTF-8")
    return(paste(content, collapse = " "))
  }, error = function(e) {
    return(NULL)
  })
}

clean_text <- function(text, remove_accents = TRUE) {
  if (remove_accents) {
    text <- remove_greek_accents(text)
  }
  text <- gsub("\\s+", " ", text)
  return(trimws(text))
}

# ═══════════════════════════════════════════════════════════
# זיהוי ציטוטים
# ═══════════════════════════════════════════════════════════

detect_citations_fast <- function(source_text, target_files, ngram_size = 6, similarity_threshold = 0.95) {
  
  message("\n╔════════════════════════════════════════════════╗")
  message("║  שלב 4: ניתוח ציטוטים                         ║")
  message("╚════════════════════════════════════════════════╝")
  
  message("\nמכין את טקסט המקור...")
  source_clean <- clean_text(source_text, remove_accents = TRUE)
  source_words <- unlist(strsplit(source_clean, "\\s+"))
  source_words <- source_words[nchar(source_words) > 0]
  
  message(paste("  • טקסט המקור:", format(length(source_words), big.mark = ","), "מילים"))
  message(paste("  • בונה hash table של n-grams (n =", ngram_size, ")..."))
  
  source_ngrams_hash <- new.env(hash = TRUE, size = length(source_words))
  ngram_count <- 0
  
  for (i in 1:(length(source_words) - ngram_size + 1)) {
    ngram <- paste(source_words[i:(i + ngram_size - 1)], collapse = " ")
    if (!exists(ngram, envir = source_ngrams_hash)) {
      source_ngrams_hash[[ngram]] <- i
      ngram_count <- ngram_count + 1
    }
  }
  
  message(paste("  • נוצרו", format(ngram_count, big.mark = ","), "n-grams ייחודיים"))
  message(paste("  • סף דמיון:", similarity_threshold * 100, "%"))
  
  use_fuzzy <- similarity_threshold < 1.0
  
  process_file_fast <- function(target_file_info) {
    target_file <- target_file_info$path
    file_idx <- target_file_info$idx
    total <- target_file_info$total
    
    if (file_idx %% 2 == 0) {
      percent <- round(file_idx / total * 100, 1)
      message(paste("  [", file_idx, "/", total, "] -", percent, "%"))
    }
    
    target_text <- fast_read_file(target_file)
    if (is.null(target_text) || nchar(target_text) == 0) return(NULL)
    
    target_clean <- clean_text(target_text, remove_accents = TRUE)
    target_words <- unlist(strsplit(target_clean, "\\s+"))
    target_words <- target_words[nchar(target_words) > 0]
    
    if (length(target_words) < ngram_size) return(NULL)
    
    matches <- list()
    found_positions <- c()
    
    for (j in 1:(length(target_words) - ngram_size + 1)) {
      if (j %in% found_positions) next
      
      target_ngram <- paste(target_words[j:(j + ngram_size - 1)], collapse = " ")
      
      if (exists(target_ngram, envir = source_ngrams_hash)) {
        source_pos <- source_ngrams_hash[[target_ngram]]
        found_positions <- c(found_positions, (j):(j + ngram_size - 1))
        
        source_context_start <- max(1, source_pos - 5)
        source_context_end <- min(length(source_words), source_pos + ngram_size + 4)
        source_context <- paste(source_words[source_context_start:source_context_end], collapse = " ")
        
        target_context_start <- max(1, j - 5)
        target_context_end <- min(length(target_words), j + ngram_size + 4)
        target_context <- paste(target_words[target_context_start:target_context_end], collapse = " ")
        
        matches[[length(matches) + 1]] <- list(
          source_text = source_context,
          target_text = target_context,
          matched_words = target_ngram,
          ngram_length = ngram_size,
          similarity_score = 1.0,
          target_file = basename(target_file)
        )
      }
    }
    
    if (length(matches) > 0) {
      df <- do.call(rbind, lapply(matches, function(m) {
        data.frame(
          source_text = m$source_text,
          target_text = m$target_text,
          matched_words = m$matched_words,
          ngram_length = m$ngram_length,
          similarity_score = m$similarity_score,
          target_file = m$target_file,
          stringsAsFactors = FALSE
        )
      }))
      
      return(list(file = basename(target_file), matches = df))
    }
    
    return(NULL)
  }
  
  file_list <- lapply(seq_along(target_files), function(i) {
    list(path = target_files[i], idx = i, total = length(target_files))
  })
  
  message("\nמעבד קבצים...\n")
  
  all_results <- lapply(file_list, process_file_fast)
  all_results <- all_results[!sapply(all_results, is.null)]
  
  results <- list()
  for (res in all_results) {
    results[[res$file]] <- res$matches
  }
  
  return(results)
}

# ═══════════════════════════════════════════════════════════
# יצירת תוצרים (כל הפונקציות מהגרסאות הקודמות)
# ═══════════════════════════════════════════════════════════

create_excel_output <- function(results, output_path) {
  wb <- createWorkbook()
  addWorksheet(wb, sheetName = "Summary")
  
  summary_data <- data.frame(
    Document = character(),
    Citations = integer(),
    Avg_Similarity = numeric(),
    Max_NGram = integer(),
    stringsAsFactors = FALSE
  )
  
  for (doc_name in names(results)) {
    df <- results[[doc_name]]
    summary_data <- rbind(summary_data, data.frame(
      Document = substr(doc_name, 1, 50),
      Citations = nrow(df),
      Avg_Similarity = round(mean(df$similarity_score), 3),
      Max_NGram = max(df$ngram_length),
      stringsAsFactors = FALSE
    ))
  }
  
  summary_data <- summary_data[order(-summary_data$Citations), ]
  writeData(wb, sheet = "Summary", x = summary_data)
  
  header_style <- createStyle(textDecoration = "bold", fontSize = 12, 
                               halign = "center", fgFill = "#4F81BD", fontColour = "#FFFFFF")
  addStyle(wb, sheet = "Summary", header_style, rows = 1, cols = 1:4, gridExpand = TRUE)
  setColWidths(wb, sheet = "Summary", cols = 1:4, widths = c(50, 15, 15, 15))
  
  top_docs <- head(names(results)[order(-sapply(results, nrow))], 20)
  
  for (doc_name in top_docs) {
    sheet_name <- substr(gsub("[:\\\\/*?\\[\\]]", "_", doc_name), 1, 31)
    addWorksheet(wb, sheetName = sheet_name)
    
    df <- results[[doc_name]]
    writeData(wb, sheet = sheet_name, x = df)
    addStyle(wb, sheet = sheet_name, header_style, rows = 1, cols = 1:6, gridExpand = TRUE)
    setColWidths(wb, sheet = sheet_name, cols = 1:6, widths = c(45, 45, 35, 10, 10, 35))
  }
  
  saveWorkbook(wb, output_path, overwrite = TRUE)
  message(paste("✓ Excel:", basename(output_path)))
}

create_basic_graph <- function(results, output_path) {
  if (length(results) == 0) return(NULL)
  
  graph_data <- data.frame(
    document = names(results),
    citations = sapply(results, nrow),
    avg_sim = sapply(results, function(df) mean(df$similarity_score)),
    stringsAsFactors = FALSE
  )
  
  graph_data <- graph_data[order(-graph_data$citations), ]
  if (nrow(graph_data) > 20) graph_data <- graph_data[1:20, ]
  
  graph_data$doc_short <- sapply(graph_data$document, function(x) {
    if (nchar(x) > 40) paste0(substr(x, 1, 37), "...") else x
  })
  
  p <- ggplot(graph_data, aes(x = reorder(doc_short, citations), y = citations, fill = avg_sim)) +
    geom_bar(stat = "identity") +
    scale_fill_gradient(low = "#FFE599", high = "#38761D", name = "דמיון ממוצע") +
    coord_flip() +
    labs(title = "20 מסמכים עם הכי הרבה ציטוטים", x = NULL, y = "מספר ציטוטים") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
  
  ggsave(output_path, plot = p, width = 12, height = 10, dpi = 300)
  message(paste("✓ גרף:", basename(output_path)))
}

create_citation_network <- function(results, output_path) {
  if (length(results) == 0) return(NULL)
  
  edges <- data.frame()
  for (doc_name in names(results)) {
    df <- results[[doc_name]]
    edges <- rbind(edges, data.frame(
      from = "יוסף בן מתיתיהו",
      to = substr(doc_name, 1, 40),
      value = nrow(df),
      title = paste(nrow(df), "ציטוטים"),
      stringsAsFactors = FALSE
    ))
  }
  
  nodes <- data.frame(
    id = unique(c(edges$from, edges$to)),
    label = unique(c(edges$from, edges$to)),
    stringsAsFactors = FALSE
  )
  
  nodes$color <- ifelse(nodes$id == "יוסף בן מתיתיהו", "#E63946", "#457B9D")
  nodes$size <- ifelse(nodes$id == "יוסף בן מתיתיהו", 40, 20)
  nodes$font.size <- 14
  
  net <- visNetwork(nodes, edges, width = "100%", height = "800px") %>%
    visEdges(arrows = "to", smooth = TRUE) %>%
    visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>%
    visInteraction(navigationButtons = TRUE) %>%
    visLayout(randomSeed = 42)
  
  visSave(net, file = output_path)
  message(paste("✓ רשת:", basename(output_path)))
}

create_ngram_heatmap <- function(results, output_path) {
  if (length(results) == 0 || length(unique(unlist(lapply(results, function(df) df$ngram_length)))) < 2) return(NULL)
  
  all_docs <- names(results)
  ngram_data <- data.frame()
  
  for (doc in all_docs) {
    df <- results[[doc]]
    doc_short <- substr(doc, 1, 30)
    for (n in unique(df$ngram_length)) {
      count <- sum(df$ngram_length == n)
      ngram_data <- rbind(ngram_data, data.frame(
        document = doc_short,
        ngram = paste0("n=", n),
        count = count,
        stringsAsFactors = FALSE
      ))
    }
  }
  
  top_docs <- head(names(sort(sapply(results, nrow), decreasing = TRUE)), 15)
  top_docs_short <- substr(top_docs, 1, 30)
  ngram_data <- ngram_data[ngram_data$document %in% top_docs_short, ]
  
  p <- ggplot(ngram_data, aes(x = ngram, y = document, fill = count)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "#F1FAEE", high = "#E63946", name = "ציטוטים") +
    labs(title = "התפלגות אורך ציטוטים", x = "אורך n-gram", y = NULL) +
    theme_minimal(base_size = 11) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
          axis.text.x = element_text(angle = 0), panel.grid = element_blank())
  
  ggsave(output_path, plot = p, width = 10, height = 8, dpi = 300)
  message(paste("✓ Heatmap:", basename(output_path)))
}

create_similarity_distribution <- function(results, output_path) {
  if (length(results) == 0) return(NULL)
  
  all_similarities <- unlist(lapply(results, function(df) df$similarity_score))
  
  p <- ggplot(data.frame(similarity = all_similarities), aes(x = similarity)) +
    geom_histogram(bins = 20, fill = "#457B9D", color = "white") +
    geom_vline(xintercept = median(all_similarities), 
               linetype = "dashed", color = "#E63946", size = 1) +
    annotate("text", x = median(all_similarities) + 0.02, y = Inf, vjust = 2,
             label = paste("חציון:", round(median(all_similarities), 2)),
             color = "#E63946", size = 4) +
    labs(title = "התפלגות רמת הדמיון", x = "רמת דמיון", y = "מספר ציטוטים") +
    theme_minimal(base_size = 12) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
  
  ggsave(output_path, plot = p, width = 10, height = 6, dpi = 300)
  message(paste("✓ התפלגות:", basename(output_path)))
}

create_citation_wordcloud <- function(results, output_path) {
  if (length(results) == 0) return(NULL)
  
  all_matched_words <- unlist(lapply(results, function(df) df$matched_words))
  all_words <- unlist(strsplit(all_matched_words, "\\s+"))
  word_freq <- table(all_words)
  word_freq <- sort(word_freq, decreasing = TRUE)[1:min(100, length(word_freq))]
  
  png(output_path, width = 1200, height = 800, res = 150)
  wordcloud(names(word_freq), freq = word_freq, min.freq = 2,
            colors = brewer.pal(8, "Dark2"), random.order = FALSE, rot.per = 0.2)
  dev.off()
  
  message(paste("✓ Word cloud:", basename(output_path)))
}

create_citation_treemap <- function(results, output_path) {
  if (length(results) == 0) return(NULL)
  
  tree_data <- data.frame(
    document = substr(names(results), 1, 40),
    citations = sapply(results, nrow),
    avg_similarity = sapply(results, function(df) mean(df$similarity_score)),
    stringsAsFactors = FALSE
  )
  
  png(output_path, width = 1200, height = 800, res = 150)
  treemap(tree_data, index = "document", vSize = "citations", vColor = "avg_similarity",
          type = "value", palette = "RdYlGn", title = "Treemap - ציטוטים",
          fontsize.labels = 10, fontface.labels = 2, align.labels = list(c("center", "center")),
          border.col = "white", border.lwds = 2)
  dev.off()
  
  message(paste("✓ Treemap:", basename(output_path)))
}

# ═══════════════════════════════════════════════════════════
# פונקציה ראשית
# ═══════════════════════════════════════════════════════════

run_analysis_interactive <- function() {
  
  message("\n╔════════════════════════════════════════════════╗")
  message("║         ניתוח ציטוטים - מצב אינטראקטיבי      ║")
  message("╚════════════════════════════════════════════════╝\n")
  
  source_file <- select_source_file()
  target_folder <- select_target_folder()
  params <- get_analysis_parameters(source_file, target_folder)
  
  message(paste("\n✓ שם הבדיקה:", params$name))
  message(paste("✓ N-gram:", params$ngram_size, "מילים"))
  message(paste("✓ סף דמיון:", params$similarity))
  
  message("\n════════════════════════════════════════════════")
  message("קורא קובץ מקור...")
  source_text <- fast_read_file(source_file)
  if (is.null(source_text)) stop("\n✗ לא ניתן לקרוא")
  
  message("סורק תיקיית יעד...")
  target_files <- list.files(target_folder, pattern = "\\.txt$", full.names = TRUE)
  
  if (length(target_files) == 0) stop("\n✗ לא נמצאו קבצי TXT")
  
  message(paste("✓ נמצאו", length(target_files), "קבצי TXT"))
  message("════════════════════════════════════════════════")
  
  start_time <- Sys.time()
  
  results <- detect_citations_fast(source_text, target_files, 
                                   ngram_size = params$ngram_size,
                                   similarity_threshold = params$similarity)
  
  end_time <- Sys.time()
  time_taken <- round(difftime(end_time, start_time, units = "mins"), 2)
  
  if (length(results) == 0) {
    message("\n╔════════════════════════════════════════════════╗")
    message("║           לא נמצאו ציטוטים                   ║")
    message("╚════════════════════════════════════════════════╝")
    return(NULL)
  }
  
  message("\n╔════════════════════════════════════════════════╗")
  message("║  שלב 5: יצירת תוצרים                          ║")
  message("╚════════════════════════════════════════════════╝")
  
  output_folder <- file.path(dirname(source_file), params$name)
  dir.create(output_folder, showWarnings = FALSE)
  
  message(paste("\nיוצר תיקיית פלט:", basename(output_folder)))
  
  excel_path <- file.path(output_folder, "results.xlsx")
  create_excel_output(results, excel_path)
  
  stats_path <- file.path(output_folder, "stats.csv")
  stats_df <- data.frame(
    document = names(results),
    citations = sapply(results, nrow),
    avg_similarity = sapply(results, function(df) round(mean(df$similarity_score), 3)),
    max_ngram = sapply(results, function(df) max(df$ngram_length)),
    stringsAsFactors = FALSE
  )
  write.csv(stats_df[order(-stats_df$citations), ], stats_path, row.names = FALSE, fileEncoding = "UTF-8")
  message(paste("✓ CSV:", basename(stats_path)))
  
  create_basic_graph(results, file.path(output_folder, "01_top_documents.png"))
  create_citation_network(results, file.path(output_folder, "02_citation_network.html"))
  create_ngram_heatmap(results, file.path(output_folder, "03_ngram_heatmap.png"))
  create_similarity_distribution(results, file.path(output_folder, "04_similarity_distribution.png"))
  create_citation_wordcloud(results, file.path(output_folder, "05_citation_wordcloud.png"))
  create_citation_treemap(results, file.path(output_folder, "06_citation_treemap.png"))
  
  message("\n╔════════════════════════════════════════════════╗")
  message("║              ✓ הושלם בהצלחה!                  ║")
  message("╚════════════════════════════════════════════════╝")
  message("\nסיכום:")
  message(paste("  • שם:", params$name))
  message(paste("  • N-gram:", params$ngram_size))
  message(paste("  • סף דמיון:", params$similarity))
  message(paste("  • מסמכים:", length(results)))
  message(paste("  • ציטוטים:", sum(sapply(results, nrow))))
  message(paste("  • זמן:", time_taken, "דקות"))
  message(paste("  • תיקייה:", basename(output_folder)))
  message("")
  
  return(list(results = results, folder = output_folder, params = params))
}

# ═══════════════════════════════════════════════════════════
# הרצה
# ═══════════════════════════════════════════════════════════

run_analysis_interactive()
